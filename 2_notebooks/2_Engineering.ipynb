{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging Champion Model (Mlean Flavor) for GCP deployment\n",
    "\n",
    "This notebook walks through the process of:\n",
    "\n",
    "    1. Write and run PySpark jobs on Cloud Dataproc for deploying the model in batch\n",
    "    2. Saving the model with MLflow (Mleap flavor)\n",
    "    3. Store Model in Github\n",
    "\n",
    "#### Author: \n",
    "\n",
    "**Nardini, Ivan - Sr. Customer Advisor | CI & Analytics Team | ModelOps & Decisioning**\n",
    "\n",
    "## Setup\n",
    "\n",
    "Mleap needs jar files (inside SPARK_HOME/jars). Some of them are:\n",
    "\n",
    "1. mleap-spark-base_2.11-0.7.0.jar\n",
    "2. mleap-core_2.11-0.7.0.jar\n",
    "3. mleap-runtime_2.11-0.7.0.jar\n",
    "4. mleap-spark_2.11-0.7.0.jar\n",
    "5. bundle-ml_2.11-0.7.0.jar\n",
    "6. config-0.3.0.jar\n",
    "7. scalapb-runtime_2.11-0.6.1.jar\n",
    "8. mleap-tensor_2.11-0.7.0.jar\n",
    "\n",
    "and then installed using pip mleap (0.7.0) - MLeap Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pyspark\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mleap==0.15.0 in /opt/conda/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from mleap==0.15.0) (1.18.1)\n",
      "Requirement already satisfied: pandas>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from mleap==0.15.0) (1.0.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from mleap==0.15.0) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.dev0 in /opt/conda/lib/python3.7/site-packages (from mleap==0.15.0) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.13.0b1 in /opt/conda/lib/python3.7/site-packages (from mleap==0.15.0) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.18.1->mleap==0.15.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.18.1->mleap==0.15.0) (2019.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.18.dev0->mleap==0.15.0) (0.14.1)\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-2.4.5.tar.gz (217.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 217.8 MB 4.0 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.7\n",
      "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=aa43968732d3d43923a0e4cd6297a76f9bf061fa63616cebe8e7ca3e1dd2425d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/01/c0/03/1c241c9c482b647d4d99412a98a5c7f87472728ad41ae55e1e\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install mleap==0.15.0\n",
    "!pip install pyspark==2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Kernel\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple MLflow project programmatically with:\n",
    "\n",
    "1. Create a Bucket\n",
    "\n",
    "2. Create pyspark job for scoring: score.py\n",
    "\n",
    "3. Create the .sh  entrypoint file to: \n",
    "\n",
    "    - Create a Spark cluster\n",
    "    - Install Mleap and Jars\n",
    "    - Run Batch Scoring Job based on score.py in cloud bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-demo-databrick-gcp'\n",
    "PROJECT = 'gel-sassandbox'\n",
    "REGION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "# print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-demo-databrick-gcp/...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create pyspark job for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import mleap.pyspark\n",
    "from mleap.pyspark.spark_support import SimpleSparkSerializer\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "\n",
    "def read_data_csv(spark, inputPath_CSV):\n",
    "    \n",
    "    '''\n",
    "    Function to load data in the Spark Session \n",
    "    :param spark: spark session \n",
    "    :param inputPath: path to get the data \n",
    "    :return: df\n",
    "    '''\n",
    "    \n",
    "    print('Trying to read the data...')\n",
    "    \n",
    "    try:\n",
    "        schema = StructType([\n",
    "          StructField('crim',DoubleType(),True),\n",
    "          StructField('zn',DoubleType(),True),\n",
    "          StructField('indus',DoubleType(),True),\n",
    "          StructField('chas',IntegerType(),True),\n",
    "          StructField('nox',DoubleType(),True),\n",
    "          StructField('rm',DoubleType(),True),\n",
    "          StructField('age',DoubleType(),True),\n",
    "          StructField('dis',DoubleType(),True),\n",
    "          StructField('rad',IntegerType(),True),\n",
    "          StructField('tax',IntegerType(),True),\n",
    "          StructField('ptratio',DoubleType(),True),\n",
    "          StructField('b',DoubleType(),True),\n",
    "          StructField('lstat',DoubleType(),True),\n",
    "          StructField('medv',DoubleType(),True)]\n",
    "        )\n",
    "        \n",
    "        df = (spark.read\n",
    "          .option(\"HEADER\", True)\n",
    "          .schema(schema)\n",
    "          .csv(inputPath_CSV))\n",
    "    \n",
    "    except ValueError:\n",
    "        print('At least, one variable format is wrong! Please check the data')\n",
    "      \n",
    "    else:\n",
    "        print('Data to score have been read successfully!')\n",
    "        return df\n",
    "\n",
    "def preprocessing(df):\n",
    "\n",
    "    '''\n",
    "    Function to preprocess data \n",
    "    :param df: A pyspark DataFrame \n",
    "    :return: abt_to_score\n",
    "    '''\n",
    "    \n",
    "    print('Data preprocessing...')\n",
    "\n",
    "    features = df.schema.names[:-1]\n",
    "    assembler_features = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "    abt_to_score = assembler_features.transform(df)\n",
    "    \n",
    "    print('Data have been processed successfully!')\n",
    "    return abt_to_score\n",
    "\n",
    "def score_data(abt_to_score, modelPath):\n",
    "    \n",
    "    '''\n",
    "    Function to score data \n",
    "    :param abt_to_score: A pyspark DataFrame to score\n",
    "    :param modelPath: The modelpath associated to .zip mleap flavor\n",
    "    :return: scoredData\n",
    "    '''\n",
    "    print('Scoring process starts...')\n",
    "    \n",
    "    deserializedPipeline = PipelineModel.deserializeFromBundle(\"jar:file:{}\".format(modelPath))\n",
    "    scoredData = deserializedPipeline.transform(abt_to_score)\n",
    "    return scoredData  \n",
    "  \n",
    "def write_output_csv(scoredData, outputPath_CSV):\n",
    "    '''\n",
    "    Function to write predictions\n",
    "    :param scoredData: A pyspark DataFrame of predictions\n",
    "    :param outputPath: The path to write the ouput table\n",
    "    :return: scoredData\n",
    "    '''\n",
    "    print('Writing Prediction in {}'.format(outputPath_CSV))\n",
    "    scoredData.toPandas().to_csv(outputPath_CSV, sep=',', index=False)\n",
    "    return scoredData.toPandas().to_dict()\n",
    "\n",
    "def evaluator(predictions):\n",
    "    \n",
    "    '''\n",
    "    Function to produce some evaluation stats\n",
    "    :param predictions: A pyspark DataFrame of predictions\n",
    "    :return: rmse, mse, r2, mae\n",
    "    '''\n",
    "    evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"medv\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    mse = evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\n",
    "    r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "    mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "    \n",
    "    return rmse, mse, r2, mae\n",
    "\n",
    "def main():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Score')\n",
    "    \n",
    "    parser.add_argument('--input', dest=\"inputpath_CSV\",\n",
    "                        required=True, help='Provide the input path of data to score')\n",
    "    \n",
    "    parser.add_argument('--model', dest=\"modelPath\",\n",
    "                        required=True, help='Provide the model path to score')\n",
    "    \n",
    "    parser.add_argument('--output', dest=\"outputpath_CSV\",\n",
    "                        required=True, help='Provide the model path to score')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    input_path_CSV = args.inputpath_CSV\n",
    "    modelPath = args.modelPath\n",
    "    output_path_CSV = args.outputpath_CSV\n",
    "  \n",
    "    try:\n",
    "#         spark = SparkSession \\\n",
    "#         .builder \\\n",
    "#         .master(SPARK_MASTER) \\\n",
    "#         .config('spark.executor.memory', TOTAL_MEMORY) \\\n",
    "#         .config('spark.cores.max', TOTAL_CORES) \\\n",
    "#         .config('spark.jars.packages',\n",
    "#                 'ml.combust.mleap:mleap-spark-base_2.11:0.9.3,ml.combust.mleap:mleap-spark_2.11:0.9.3') \\\n",
    "#         .appName(\"RegressionScoring\") \\\n",
    "#         .getOrCreate()\n",
    "        spark = SparkSession.builder.appName('RegressionScoring').getOrCreate()\n",
    "        spark.sparkContext.setLogLevel(\"OFF\")\n",
    "        print('Created a SparkSession')\n",
    "    \n",
    "    except ValueError:\n",
    "        warnings.warn('Check')\n",
    "  \n",
    "    #Read data\n",
    "    data_to_process = read_data_csv(spark, input_path_CSV)\n",
    "    #Preprocessing\n",
    "    abt = preprocessing(data_to_process)\n",
    "    #Scoring\n",
    "    abt_scored = score_data(abt, modelPath)\n",
    "    #Write data\n",
    "    write_output_csv(abt_scored, output_path_CSV)\n",
    "    #Evaluate Model\n",
    "    evalstats = evaluator(abt_scored)\n",
    "    return evalstats\n",
    "    \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    stats = main()\n",
    "    print('-'*20)\n",
    "    print('Process Log')\n",
    "    print('-'*20)\n",
    "    print('Scoring Job ends successfully!')\n",
    "    print(\"RMSE for the model: {}\".format(stats[0]))\n",
    "    print(\"MSE for the model: {}\".format(stats[1]))\n",
    "    print(\"R2 for the model: {}\".format(stats[2]))\n",
    "    print(\"MAE for the model: {}\".format(stats[3]))\n",
    "    print('Look at the Storage Bucket to get predictions!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a SparkSession\n",
      "Trying to read the data...\n",
      "Data to score have been read successfully!\n",
      "Data preprocessing...\n",
      "Data have been processed successfully!\n",
      "Scoring process starts...\n",
      "Writing Prediction in /home/jovyan/work/1_data/boston_house_prices_scored.csv\n",
      "--------------------\n",
      "Process Log\n",
      "--------------------\n",
      "Scoring Job ends successfully!\n",
      "RMSE for the model: 4.696684029858866\n",
      "MSE for the model: 22.05884087633132\n",
      "R2 for the model: 0.7386998714429953\n",
      "MAE for the model: 3.3284024432759862\n",
      "Look at the Storage Bucket to get predictions!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/04/17 08:57:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python score.py --input \"/home/jovyan/work/1_data/boston_house_prices.csv\" \\\n",
    "    --model \"/home/jovyan/work/2_notebooks/output/ModelProjects_Boston_ML_lrModel.zip\"\\\n",
    "    --output  \"/home/jovyan/work/1_data/boston_house_prices_scored.csv\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "2_Enginerring",
  "notebookId": 3075853380345907
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
